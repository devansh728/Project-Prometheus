"""
FastAPI WebSocket Orchestrator for Real-time EV Telemetry Inference
====================================================================
Provides WebSocket endpoint for streaming telemetry and returns real-time predictions.

Usage:
    uvicorn fastapi_orchestrator:app --host 0.0.0.0 --port 8000
"""

import json
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from collections import defaultdict

import numpy as np
import pandas as pd
import lightgbm as lgb
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel


# Configuration
BASE_DIR = Path(__file__).parent.parent
MODELS_DIR = BASE_DIR / "models"
CONFIG_PATH = BASE_DIR / "config.json"


class TelemetryFrame(BaseModel):
    """Single telemetry frame from vehicle."""

    vehicle_id: str
    timestamp: int
    speed_kph: float = 0
    motor_rpm: float = 0
    motor_temp_c: float = 25
    inverter_temp_c: float = 25
    battery_soc_pct: float = 80
    battery_voltage_v: float = 400
    battery_current_a: float = 0
    battery_temp_c: float = 25
    battery_cell_delta_v: float = 0.05
    hvac_power_kw: float = 0
    throttle_pct: int = 0
    brake_pct: int = 0
    regen_pct: int = 0
    accel_x: float = 0
    accel_y: float = 0
    accel_z: float = 1
    charging_state: str = "idle"
    dtc_codes: List[str] = []


class Alert(BaseModel):
    """Alert generated by the system."""

    vehicle_id: str
    timestamp: int
    alert_type: str  # "anomaly" or "failure_prediction"
    severity: str  # "low", "medium", "high", "critical"
    probability: float
    message: str
    recommended_action: str


class VehicleBuffer:
    """Maintains per-vehicle telemetry buffer for window computation."""

    def __init__(self, window_size: int = 300, stride: int = 60):
        self.window_size = window_size
        self.stride = stride
        self.frames: List[Dict] = []
        self.last_inference_ts = 0
        self.alerts: List[Alert] = []

    def add_frame(self, frame: TelemetryFrame) -> Optional[pd.DataFrame]:
        """Add frame and return window if ready for inference."""
        self.frames.append(frame.model_dump())

        # Keep only frames within window
        if len(self.frames) > self.window_size * 2:
            self.frames = self.frames[-self.window_size :]

        # Check if enough time passed for new inference
        current_ts = frame.timestamp
        if (
            current_ts - self.last_inference_ts >= self.stride
            and len(self.frames) >= self.window_size
        ):
            self.last_inference_ts = current_ts
            return self._compute_window_features()

        return None

    def _compute_window_features(self) -> pd.DataFrame:
        """Compute aggregated features for the current window."""
        df = pd.DataFrame(self.frames[-self.window_size :])

        numeric_cols = [
            "speed_kph",
            "motor_rpm",
            "motor_temp_c",
            "inverter_temp_c",
            "battery_soc_pct",
            "battery_voltage_v",
            "battery_current_a",
            "battery_temp_c",
            "battery_cell_delta_v",
            "hvac_power_kw",
            "throttle_pct",
            "brake_pct",
            "regen_pct",
            "accel_x",
            "accel_y",
            "accel_z",
        ]

        features = {}
        for col in numeric_cols:
            if col in df.columns:
                series = df[col].dropna()
                if len(series) > 0:
                    features[f"{col}_mean"] = series.mean()
                    features[f"{col}_std"] = series.std()
                    features[f"{col}_min"] = series.min()
                    features[f"{col}_max"] = series.max()

        # Derived features
        features["power_kw_mean"] = (
            features.get("battery_voltage_v_mean", 0)
            * features.get("battery_current_a_mean", 0)
            / 1000
        )
        features["accel_magnitude_mean"] = np.sqrt(
            features.get("accel_x_mean", 0) ** 2
            + features.get("accel_y_mean", 0) ** 2
            + features.get("accel_z_mean", 0) ** 2
        )

        return pd.DataFrame([features])


class InferenceEngine:
    """Handles model loading and inference."""

    def __init__(self, models_dir: Path):
        self.models_dir = models_dir
        self.failure_model = None
        self.severity_model = None
        self.feature_columns = []
        self.thresholds = {}
        self._load_models()

    def _load_models(self):
        """Load trained models and configurations."""
        print("Loading models...")

        # Load failure predictor
        failure_path = self.models_dir / "lgbm_failure_predictor.txt"
        if failure_path.exists():
            self.failure_model = lgb.Booster(model_file=str(failure_path))
            print("  Loaded failure predictor")

        # Load severity classifier
        severity_path = self.models_dir / "lgbm_severity_classifier.txt"
        if severity_path.exists():
            self.severity_model = lgb.Booster(model_file=str(severity_path))
            print("  Loaded severity classifier")

        # Load feature columns
        features_path = self.models_dir / "feature_columns.json"
        if features_path.exists():
            with open(features_path, "r") as f:
                self.feature_columns = json.load(f)
            print(f"  Loaded {len(self.feature_columns)} feature columns")

        # Load thresholds
        thresholds_path = self.models_dir / "thresholds.json"
        if thresholds_path.exists():
            with open(thresholds_path, "r") as f:
                self.thresholds = json.load(f)
            print(f"  Loaded thresholds: {self.thresholds}")

    def predict(self, features_df: pd.DataFrame) -> Dict:
        """Run inference on feature dataframe."""
        # Prepare features (fill missing with 0)
        X = pd.DataFrame(columns=self.feature_columns)
        for col in self.feature_columns:
            if col in features_df.columns:
                X[col] = features_df[col].values
            else:
                X[col] = 0
        X = X.fillna(0).values

        result = {
            "failure_probability": 0.0,
            "severity": "low",
            "is_anomaly": False,
            "failure_predicted": False,
        }

        # Failure prediction
        if self.failure_model:
            proba = self.failure_model.predict(X)[0]
            result["failure_probability"] = float(
                proba
            )  # Convert to native Python float

            threshold = self.thresholds.get("failure_predictor", {}).get(
                "high_precision_threshold", 0.5
            )
            result["failure_predicted"] = bool(
                proba >= threshold
            )  # Convert to native Python bool

        # Severity prediction
        if self.severity_model and result.get("failure_predicted"):
            severity_proba = self.severity_model.predict(X)[0]
            severity_idx = int(np.argmax(severity_proba))
            severity_map = {0: "low", 1: "medium", 2: "high", 3: "critical"}
            result["severity"] = severity_map.get(severity_idx, "low")

        return result


class ConnectionManager:
    """Manages WebSocket connections."""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]

    async def broadcast(self, message: dict):
        for ws in self.active_connections.values():
            try:
                await ws.send_json(message)
            except:
                pass


# Initialize FastAPI app
app = FastAPI(
    title="EV Telemetry Inference API",
    description="Real-time failure prediction and anomaly detection for EV telemetry",
    version="1.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global state
inference_engine = InferenceEngine(MODELS_DIR)
vehicle_buffers: Dict[str, VehicleBuffer] = defaultdict(VehicleBuffer)
connection_manager = ConnectionManager()
alerts_log: List[Alert] = []


@app.get("/")
async def root():
    return {"status": "running", "service": "EV Telemetry Inference API"}


@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "models_loaded": {
            "failure_predictor": inference_engine.failure_model is not None,
            "severity_classifier": inference_engine.severity_model is not None,
        },
        "active_vehicles": len(vehicle_buffers),
        "total_alerts": len(alerts_log),
    }


@app.post("/telemetry")
async def ingest_telemetry(frame: TelemetryFrame):
    """HTTP endpoint for single telemetry frame."""
    buffer = vehicle_buffers[frame.vehicle_id]
    window_features = buffer.add_frame(frame)

    response = {"status": "received", "vehicle_id": frame.vehicle_id}

    if window_features is not None:
        prediction = inference_engine.predict(window_features)
        response["prediction"] = prediction

        # Generate alert if needed
        if prediction.get("failure_predicted") or prediction.get("is_anomaly"):
            alert = create_alert(frame, prediction)
            alerts_log.append(alert)
            buffer.alerts.append(alert)
            response["alert"] = alert.model_dump()

    return response


@app.websocket("/ws/telemetry")
async def websocket_telemetry(websocket: WebSocket):
    """WebSocket endpoint for streaming telemetry."""
    await connection_manager.connect(websocket, str(id(websocket)))

    try:
        while True:
            data = await websocket.receive_json()
            frame = TelemetryFrame(**data)

            buffer = vehicle_buffers[frame.vehicle_id]
            window_features = buffer.add_frame(frame)

            if window_features is not None:
                prediction = inference_engine.predict(window_features)

                response = {
                    "type": "prediction",
                    "vehicle_id": frame.vehicle_id,
                    "timestamp": frame.timestamp,
                    "prediction": prediction,
                }

                # Generate alert if needed
                if prediction.get("failure_predicted") or prediction.get("is_anomaly"):
                    alert = create_alert(frame, prediction)
                    alerts_log.append(alert)
                    response["alert"] = alert.model_dump()

                await websocket.send_json(response)

    except WebSocketDisconnect:
        connection_manager.disconnect(str(id(websocket)))


@app.get("/vehicles")
async def list_vehicles():
    """List all active vehicles with their status."""
    vehicles = []
    for vehicle_id, buffer in vehicle_buffers.items():
        vehicles.append(
            {
                "vehicle_id": vehicle_id,
                "frames_buffered": len(buffer.frames),
                "last_inference_ts": buffer.last_inference_ts,
                "alert_count": len(buffer.alerts),
            }
        )
    return {"vehicles": vehicles}


@app.get("/alerts")
async def get_alerts(vehicle_id: Optional[str] = None, limit: int = 100):
    """Get recent alerts."""
    alerts = alerts_log
    if vehicle_id:
        alerts = [a for a in alerts if a.vehicle_id == vehicle_id]
    return {"alerts": [a.model_dump() for a in alerts[-limit:]]}


@app.get("/thresholds")
async def get_thresholds():
    """Get current inference thresholds."""
    return inference_engine.thresholds


def create_alert(frame: TelemetryFrame, prediction: Dict) -> Alert:
    """Create an alert from a prediction."""
    severity = prediction.get("severity", "low")
    probability = prediction.get("failure_probability", 0)

    severity_messages = {
        "low": "Minor issue detected. Schedule routine maintenance.",
        "medium": "Moderate issue detected. Inspect within 1 week.",
        "high": "Significant issue detected. Service recommended within 48 hours.",
        "critical": "CRITICAL: Immediate attention required. Schedule service now.",
    }

    severity_actions = {
        "low": "Monitor and schedule next regular service appointment.",
        "medium": "Run diagnostics and inspect flagged components.",
        "high": "Contact service center and avoid extended driving.",
        "critical": "Stop driving if safe. Contact roadside assistance.",
    }

    return Alert(
        vehicle_id=frame.vehicle_id,
        timestamp=frame.timestamp,
        alert_type="failure_prediction",
        severity=severity,
        probability=probability,
        message=severity_messages.get(severity, "Issue detected."),
        recommended_action=severity_actions.get(severity, "Contact service."),
    )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
